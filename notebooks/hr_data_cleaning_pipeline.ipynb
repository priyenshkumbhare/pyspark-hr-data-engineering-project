{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa09afd",
   "metadata": {},
   "source": [
    "## 1. Project Overview\n",
    "##### Dataset Description\n",
    "\n",
    "This dataset contains employee records including employee ID, department, salary, joining date, and other HR-related attributes.\n",
    "\n",
    "The data simulates a real-world HR system where employee records may contain inconsistencies, missing values, and formatting issues.\n",
    "Explain:\n",
    "\n",
    "##### Data Problems Identified\n",
    "\n",
    "During initial exploration, the following issues were observed:\n",
    "\n",
    "- Missing values in key columns\n",
    "\n",
    "- Inconsistent formatting (e.g., department names values)\n",
    "\n",
    "- Duplicate employee records\n",
    "\n",
    "- Incorrect or unrealistic salary values\n",
    "\n",
    "- Mixed date formats\n",
    "\n",
    "These issues require cleaning before the data can be reliably used for reporting or downstream systems\n",
    "\n",
    "##### Tools & Technologies Used\n",
    "\n",
    "- PySpark – Distributed data processing\n",
    "\n",
    "- Spark SQL – Querying structured data\n",
    "\n",
    "- DataFrame API – Data cleaning and transformation\n",
    "\n",
    "- Jupyter Notebook – Development environment\n",
    "\n",
    "##### Goal of the project\n",
    "The objective of this project is to:\n",
    "\n",
    "- Clean and standardize employee data\n",
    "\n",
    "- Handle missing and duplicate records\n",
    "\n",
    "- Validate and transform columns\n",
    "\n",
    "- Prepare production-ready structured data\n",
    "\n",
    "- Simulate a real-world data engineering cleaning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0b78ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up pyspark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark=SparkSession.builder\\\n",
    ".appName(\"HrDataCleaning\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce01f6",
   "metadata": {},
   "source": [
    "## 2. Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd222eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw HR Data\n",
      "+-----------+-----------+---------------+------+------------+--------------------+\n",
      "|employee_id|       name|     department|salary|joining_date|               email|\n",
      "+-----------+-----------+---------------+------+------------+--------------------+\n",
      "|        E82| Employee_1|             IT|-31639|    2/4/2020| Employee1@Compan...|\n",
      "|        E87| Employee_2|        finance|78,540|    7/3/2019| Employee2@Compan...|\n",
      "|        E28| Employee_3|          sales|45,247|   2/12/2020| Employee3@Compan...|\n",
      "|        E29| Employee_4|             hr|59,439|  11/30/2022| Employee4@Compan...|\n",
      "|        E36| Employee_5|Human Resources|-44110|    7/9/2019| Employee5@Compan...|\n",
      "|        E46| Employee_6|             HR|-52541|    2/3/2023| Employee6@Compan...|\n",
      "|        E49| Employee_7|             IT|-66178|  13-12-2022| Employee7@Compan...|\n",
      "|        E85| Employee_8|             IT|44,935|   7/26/2019| Employee8@Compan...|\n",
      "|        E59| Employee_9|        Finance|  NULL|  28-12-2020| Employee9@Compan...|\n",
      "|        E90|Employee_10|          sales|  NULL|    2/2/2023| Employee10@Compa...|\n",
      "+-----------+-----------+---------------+------+------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- joining_date: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load raw data\n",
    "df_raw=spark.read.format(\"csv\")\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".load(\"../raw_data/raw_hr_data.csv\")\n",
    "\n",
    "#printting raw data\n",
    "print(\"Raw HR Data\")\n",
    "df_raw.show(10)\n",
    "\n",
    "#schema of raw_hr_data\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4f23e",
   "metadata": {},
   "source": [
    "## 3. Initial data assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c209771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows:100\n",
      "Duplicate Rows:38\n",
      "Missing Salary Count:19\n",
      "Unique Rows:62\n"
     ]
    }
   ],
   "source": [
    "# 1> total rows\n",
    "total_rows=df_raw.count()\n",
    "\n",
    "# 2. Duplicate count\n",
    "# for this we subtract thw count of unique to the total rows\n",
    "df_unique=df_raw.dropDuplicates([\"employee_id\"])\n",
    "unique_rows=df_unique.count()\n",
    "duplicate_row=total_rows-unique_rows\n",
    "\n",
    "#3. Missing Salary Count\n",
    "#for checking actual NULL values in the salary column\n",
    "missing_salary=df_raw.filter(col(\"salary\").isNull()).count()\n",
    "\n",
    "#Displaying Results\n",
    "print(f\"Total Rows:{total_rows}\")\n",
    "print(f\"Duplicate Rows:{duplicate_row}\")\n",
    "print(f\"Missing Salary Count:{missing_salary}\")\n",
    "print(f\"Unique Rows:{unique_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a5f9a",
   "metadata": {},
   "source": [
    "## 4. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94294b0d",
   "metadata": {},
   "source": [
    "### 4.1 Salary Cleaning and Validation\n",
    "#### Data Quality Issues Identified\n",
    "\n",
    "During initial validation of the salary column, the following issues were observed:\n",
    "\n",
    "- 19 records contained NULL values\n",
    "\n",
    "- 11 records contained negative salary values\n",
    "\n",
    "- Several records were formatted as strings with commas (e.g., \"45,000\")\n",
    "\n",
    "- Empty string values were present\n",
    "\n",
    "Total affected salary records: 30\n",
    "\n",
    "#### Data Cleaning Actions Performed\n",
    "\n",
    "The following transformations were applied:\n",
    "\n",
    "- Removed comma formatting from salary values\n",
    "\n",
    "- Converted salary column to numeric type\n",
    "\n",
    "- Standardized empty strings to NULL\n",
    "\n",
    "- Treated negative salary values as invalid\n",
    "\n",
    "- Imputed missing and invalid salaries using department-level median\n",
    "\n",
    "A salary_flag column was created to preserve audit traceability and distinguish between original and imputed values.\n",
    "\n",
    "#### Business Rationale\n",
    "\n",
    "Negative salary values are invalid in an HR payroll context.\n",
    "To prevent incorrect financial reporting and maintain payroll consistency, these records were treated as missing and imputed using department-level median values.\n",
    "\n",
    "This approach ensures data integrity while preserving the original business meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40658e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Rows: 62\n",
      "Actual Missing Salary after cleaning: 30\n"
     ]
    }
   ],
   "source": [
    "# 1. replace empty string with NULL\n",
    "df_salary=df_unique.withColumn(\"salary\",\n",
    "                            when(col(\"salary\")==\"\", None).otherwise(col(\"salary\"))\n",
    "                            )\n",
    "\n",
    "#2. remove commas\n",
    "df_salary=df_salary.withColumn(\"salary\",\n",
    "                               regexp_replace(col(\"salary\"),\",\",\"\")\n",
    "                               )\n",
    "\n",
    "#3. converting to numeric- casting\n",
    "df_salary=df_salary.withColumn(\"salary\",\n",
    "                               col(\"salary\").cast(\"double\")\n",
    "                               )\n",
    "\n",
    "#4. flaging invalid nagative salary - insted of deleting this null salary record I create a flag\n",
    "df_salary=df_salary.withColumn(\"salary_flag\",\n",
    "                               when(col(\"salary\") < 0, \"Invalid_Negative\")\n",
    "                               .when(col(\"salary\").isNull(),\"Imputed_Department_Median\")\n",
    "                               .otherwise(\"Original_Valid\")\n",
    "                               )\n",
    "#5. remove negative salaries\n",
    "df_salary=df_salary.withColumn(\"salary\",\n",
    "                               when(col(\"salary\") < 0,None).otherwise(col(\"salary\"))\n",
    "                               )\n",
    "\n",
    "# cheking real missing salary count\n",
    "missing_salary=df_salary.filter(col(\"salary\").isNull())\n",
    "\n",
    "print(\"Total Unique Rows:\",df_salary.count())\n",
    "print(\"Actual Missing Salary after cleaning:\", missing_salary.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66482a4b",
   "metadata": {},
   "source": [
    "A salary_flag column was retained to maintain audit traceability and distinguish between original and imputed values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62853057",
   "metadata": {},
   "source": [
    "### 4.2 Standardize Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20c75cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep=df_salary.withColumn(\"department\",\n",
    "                              trim(lower(col(\"department\")))\n",
    "                              )\\\n",
    "                              .withColumn(\"department\",\n",
    "                                          when(col(\"department\").isin(\"hr\",\"human resources\"),\"Human Resources\")\n",
    "                                          .when(col(\"department\").isin(\"it\",\"information technology\"),\"Information Technology\")\n",
    "                                          .when(col(\"department\").isin(\"finance\"),\"Finance\")\n",
    "                                          .when(col(\"department\").isin(\"sales\"),\"Sales\")\n",
    "                                          .otherwise(col(\"department\"))\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15147f9",
   "metadata": {},
   "source": [
    "### 4.3 Clean Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0e81d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining date standardization- convert everything  into yyyy-MM-dd\n",
    "df_date=df_dep.withColumn(\"joining_date\",\n",
    "                             coalesce(\n",
    "                                to_date(col(\"joining_date\"),\"yyyy-MM-dd\"),\n",
    "                                to_date(col(\"joining_date\"),\"dd-MM-yyyy\"),\n",
    "                                to_date(col(\"joining_date\"),\"yyyy/MM/dd\"),\n",
    "                                to_date(col(\"joining_date\"), \"M/d/yyyy\"),\n",
    "                                to_date(col(\"joining_date\"), \"MM/dd/yyyy\"),\n",
    "                             ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c280ecde",
   "metadata": {},
   "source": [
    "### 4.4 Clean Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3508547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning email\n",
    "#leading space and uppercase letter\n",
    "df_email=df_date.withColumn(\"email\",\n",
    "                            lower(trim(col(\"email\")))\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1255299",
   "metadata": {},
   "source": [
    "Salary imputation was performed using department-level median values to preserve distribution characteristics and avoid skew from extreme values.\n",
    "### 4.5 Impute salary (dept median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72d5dfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----------+-------+------------+--------------------+--------------------+\n",
      "|          department|employee_id|       name| salary|joining_date|               email|         salary_flag|\n",
      "+--------------------+-----------+-----------+-------+------------+--------------------+--------------------+\n",
      "|Information Techn...|         E1|Employee_26|34652.0|  2019-05-19|employee26@compan...|      Original_Valid|\n",
      "|Information Techn...|        E10|Employee_27|48250.0|  2022-09-01|employee27@compan...|      Original_Valid|\n",
      "|               Sales|        E11|Employee_22|77966.0|  2019-09-15|employee22@compan...|      Original_Valid|\n",
      "|             Finance|        E12|Employee_32|67957.0|  2021-09-21|employee32@compan...|Imputed_Departmen...|\n",
      "|     Human Resources|        E14|Employee_30|42465.0|  2021-05-14|employee30@compan...|      Original_Valid|\n",
      "|     Human Resources|        E15|Employee_18|40365.0|  2023-01-18|employee18@compan...|      Original_Valid|\n",
      "|               Sales|        E16|Employee_68|82521.0|  2022-02-18|employee68@compan...|      Original_Valid|\n",
      "|     Human Resources|         E2|Employee_87|83892.0|  2021-06-06|employee87@compan...|      Original_Valid|\n",
      "|             Finance|        E20|Employee_20|54504.0|  2021-09-27|employee20@compan...|      Original_Valid|\n",
      "|             Finance|        E22|Employee_77|85083.0|  2022-04-27|employee77@compan...|      Original_Valid|\n",
      "|             Finance|        E24|Employee_91|67957.0|  2020-07-26|employee91@compan...|    Invalid_Negative|\n",
      "|               Sales|        E25|Employee_97|77138.0|  2022-05-07|employee97@compan...|    Invalid_Negative|\n",
      "|Information Techn...|        E26|Employee_53|44935.0|  2020-01-04|employee53@compan...|    Invalid_Negative|\n",
      "|               Sales|        E28| Employee_3|45247.0|  2020-02-12|employee3@company...|      Original_Valid|\n",
      "|     Human Resources|        E29| Employee_4|59439.0|  2022-11-30|employee4@company...|      Original_Valid|\n",
      "|Information Techn...|        E31|Employee_82|38272.0|  2021-08-10|employee82@compan...|      Original_Valid|\n",
      "|               Sales|        E32|Employee_25|44725.0|  2020-04-16|employee25@compan...|      Original_Valid|\n",
      "|Information Techn...|        E34|Employee_39|44935.0|  2020-06-27|employee39@compan...|    Invalid_Negative|\n",
      "|Information Techn...|        E35|Employee_44|44935.0|  2022-11-08|employee44@compan...|    Invalid_Negative|\n",
      "|     Human Resources|        E36| Employee_5|59439.0|  2019-07-09|employee5@company...|    Invalid_Negative|\n",
      "|     Human Resources|        E37|Employee_34|77874.0|  2020-01-24|employee34@compan...|      Original_Valid|\n",
      "|Information Techn...|        E38|Employee_94|44935.0|  2022-09-21|employee94@compan...|Imputed_Departmen...|\n",
      "|               Sales|        E39|Employee_75|85931.0|  2022-01-23|employee75@compan...|      Original_Valid|\n",
      "|               Sales|        E40|Employee_24|77138.0|  2021-11-25|employee24@compan...|    Invalid_Negative|\n",
      "|             Finance|        E41|Employee_12|67957.0|  2020-03-11|employee12@compan...|Imputed_Departmen...|\n",
      "|Information Techn...|        E42|Employee_60|44935.0|  2021-05-11|employee60@compan...|Imputed_Departmen...|\n",
      "|     Human Resources|        E46| Employee_6|59439.0|  2023-02-03|employee6@company...|    Invalid_Negative|\n",
      "|Information Techn...|        E47|Employee_21|44935.0|  2019-04-29|employee21@compan...|    Invalid_Negative|\n",
      "|               Sales|        E48|Employee_42|77138.0|  2019-01-17|employee42@compan...|    Invalid_Negative|\n",
      "|Information Techn...|        E49| Employee_7|44935.0|  2022-12-13|employee7@company...|    Invalid_Negative|\n",
      "|             Finance|         E5|Employee_56|67957.0|  2021-06-12|employee56@compan...|    Invalid_Negative|\n",
      "|     Human Resources|        E50|Employee_57|59439.0|  2022-12-22|employee57@compan...|    Invalid_Negative|\n",
      "|     Human Resources|        E51|Employee_13|72129.0|  2020-06-26|employee13@compan...|      Original_Valid|\n",
      "|     Human Resources|        E52|Employee_33|40789.0|  2021-03-10|employee33@compan...|      Original_Valid|\n",
      "|             Finance|        E53|Employee_51|67957.0|  2022-10-03|employee51@compan...|    Invalid_Negative|\n",
      "|               Sales|        E57|Employee_69|77138.0|  2021-02-07|employee69@compan...|      Original_Valid|\n",
      "|               Sales|        E58|Employee_70|77138.0|  2021-09-19|employee70@compan...|    Invalid_Negative|\n",
      "|             Finance|        E59| Employee_9|67957.0|  2020-12-28|employee9@company...|Imputed_Departmen...|\n",
      "|Information Techn...|         E6|Employee_46|44935.0|  2019-11-27|employee46@compan...|Imputed_Departmen...|\n",
      "|             Finance|        E60|Employee_11|67957.0|  2019-04-25|employee11@compan...|Imputed_Departmen...|\n",
      "|               Sales|        E61|Employee_95|52528.0|  2020-11-08|employee95@compan...|      Original_Valid|\n",
      "|     Human Resources|        E63|Employee_76|58562.0|  2021-03-07|employee76@compan...|      Original_Valid|\n",
      "|Information Techn...|        E65|Employee_19|79935.0|  2022-08-01|employee19@compan...|      Original_Valid|\n",
      "|     Human Resources|        E66|Employee_15|62343.0|  2019-11-10|employee15@compan...|      Original_Valid|\n",
      "|             Finance|        E67|Employee_58|67957.0|  2021-02-06|employee58@compan...|Imputed_Departmen...|\n",
      "|             Finance|        E70|Employee_48|67957.0|  2019-09-19|employee48@compan...|Imputed_Departmen...|\n",
      "|               Sales|        E71|Employee_17|86412.0|  2020-06-30|employee17@compan...|      Original_Valid|\n",
      "|             Finance|        E72|Employee_14|78956.0|  2021-11-01|employee14@compan...|      Original_Valid|\n",
      "|             Finance|        E73|Employee_86|52754.0|  2019-05-22|employee86@compan...|      Original_Valid|\n",
      "|             Finance|        E75|Employee_38|68962.0|  2022-09-08|employee38@compan...|      Original_Valid|\n",
      "|     Human Resources|        E76|Employee_85|59439.0|  2022-11-28|employee85@compan...|Imputed_Departmen...|\n",
      "|             Finance|        E77|Employee_37|67957.0|  2019-09-03|employee37@compan...|Imputed_Departmen...|\n",
      "|             Finance|         E8|Employee_35|67957.0|  2019-04-28|employee35@compan...|      Original_Valid|\n",
      "|Information Techn...|        E80|Employee_59|50572.0|  2021-11-04|employee59@compan...|      Original_Valid|\n",
      "|Information Techn...|        E82| Employee_1|44935.0|  2020-02-04|employee1@company...|    Invalid_Negative|\n",
      "|Information Techn...|        E84|Employee_81|44935.0|  2019-02-11|employee81@compan...|Imputed_Departmen...|\n",
      "|Information Techn...|        E85| Employee_8|44935.0|  2019-07-26|employee8@company...|      Original_Valid|\n",
      "|     Human Resources|        E86|Employee_40|59439.0|  2019-01-20|employee40@compan...|    Invalid_Negative|\n",
      "|             Finance|        E87| Employee_2|78540.0|  2019-07-03|employee2@company...|      Original_Valid|\n",
      "|             Finance|        E88|Employee_16|34163.0|  2022-05-05|employee16@compan...|      Original_Valid|\n",
      "|             Finance|         E9|Employee_73|51684.0|  2019-08-05|employee73@compan...|      Original_Valid|\n",
      "|               Sales|        E90|Employee_10|77138.0|  2023-02-02|employee10@compan...|Imputed_Departmen...|\n",
      "+--------------------+-----------+-----------+-------+------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. calculate department median\n",
    "dept_median=df_email.groupBy(\"department\").agg(\n",
    "    percentile_approx(\"salary\",0.5).alias(\"median_salary\")\n",
    ")\n",
    "\n",
    "#2. join back to main data\n",
    "df_dep=df_email.join(dept_median, on=\"department\",how=\"left\")\n",
    "\n",
    "#3. fill missing salary\n",
    "df_dep1=df_dep.withColumn(\"salary\",\n",
    "                               coalesce(col(\"salary\"), col(\"median_salary\"))\n",
    "                               )\n",
    "#drop helper column\n",
    "df_dep1=df_dep1.drop(\"median_salary\")\n",
    "\n",
    "#printing clean df\n",
    "df_dep1.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0decd721",
   "metadata": {},
   "source": [
    "## 5. Final schema enforcement\n",
    "\n",
    "Final schema was explicitly enforced to ensure downstream compatibility and data contract stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d00812b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      " |-- joining_date: date (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- salary_flag: string (nullable = false)\n",
      "\n",
      "+-----------+-----------+--------------------+-------+------------+--------------------+--------------------+\n",
      "|employee_id|       name|          department| salary|joining_date|               email|         salary_flag|\n",
      "+-----------+-----------+--------------------+-------+------------+--------------------+--------------------+\n",
      "|         E1|Employee_26|Information Techn...|34652.0|  2019-05-19|employee26@compan...|      Original_Valid|\n",
      "|        E10|Employee_27|Information Techn...|48250.0|  2022-09-01|employee27@compan...|      Original_Valid|\n",
      "|        E11|Employee_22|               Sales|77966.0|  2019-09-15|employee22@compan...|      Original_Valid|\n",
      "|        E12|Employee_32|             Finance|67957.0|  2021-09-21|employee32@compan...|Imputed_Departmen...|\n",
      "|        E14|Employee_30|     Human Resources|42465.0|  2021-05-14|employee30@compan...|      Original_Valid|\n",
      "+-----------+-----------+--------------------+-------+------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fixing column order\n",
    "df_clean=df_dep1.select(\"employee_id\",\"name\",\"department\",\"salary\",\n",
    "                         \"joining_date\",\"email\",\"salary_flag\")\n",
    "df_clean.printSchema()\n",
    "df_clean.show(5)\n",
    "\n",
    "df_clean.coalesce(1)\\\n",
    ".write.mode(\"overwrite\")\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".csv(\"../output/cleaned_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaf0ddf",
   "metadata": {},
   "source": [
    "## 6. Exporting invalid records to separate file (for client transparency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27aecb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+------+------------+--------------------+\n",
      "|employee_id|       name|          department|salary|joining_date|               email|\n",
      "+-----------+-----------+--------------------+------+------------+--------------------+\n",
      "|        E82| Employee_1|                  IT|-31639|    2/4/2020| Employee1@Compan...|\n",
      "|        E36| Employee_5|     Human Resources|-44110|    7/9/2019| Employee5@Compan...|\n",
      "|        E46| Employee_6|                  HR|-52541|    2/3/2023| Employee6@Compan...|\n",
      "|        E49| Employee_7|                  IT|-66178|  13-12-2022| Employee7@Compan...|\n",
      "|        E59| Employee_9|             Finance|  NULL|  28-12-2020| Employee9@Compan...|\n",
      "|        E90|Employee_10|               sales|  NULL|    2/2/2023| Employee10@Compa...|\n",
      "|        E60|Employee_11|             Finance|  NULL|  25-04-2019| Employee11@Compa...|\n",
      "|        E41|Employee_12|             Finance|  NULL|   3/11/2020| Employee12@Compa...|\n",
      "|        E47|Employee_21|                  IT|-84504|  29-04-2019| Employee21@Compa...|\n",
      "|        E40|Employee_24|               Sales|-74019|  11/25/2021| Employee24@Compa...|\n",
      "|        E12|Employee_32|             finance|  NULL|   9/21/2021| Employee32@Compa...|\n",
      "|        E77|Employee_37|             finance|  NULL|    9/3/2019| Employee37@Compa...|\n",
      "|        E34|Employee_39|                  IT|-73891|   6/27/2020| Employee39@Compa...|\n",
      "|        E86|Employee_40|     Human Resources|-49660|   1/20/2019| Employee40@Compa...|\n",
      "|        E10|Employee_41|                  hr|-43969|  15-12-2020| Employee41@Compa...|\n",
      "|        E48|Employee_42|               sales|-40338|   1/17/2019| Employee42@Compa...|\n",
      "|        E85|Employee_43|     Human Resources|-87548|    8/8/2019| Employee43@Compa...|\n",
      "|        E35|Employee_44|                  IT|-69638|   11/8/2022| Employee44@Compa...|\n",
      "|         E6|Employee_46|Information Techn...|  NULL|  11/27/2019| Employee46@Compa...|\n",
      "|        E70|Employee_48|             finance|  NULL|  19-09-2019| Employee48@Compa...|\n",
      "|        E53|Employee_51|             finance|-41754|   10/3/2022| Employee51@Compa...|\n",
      "|        E26|Employee_53|                  IT|-60166|    1/4/2020| Employee53@Compa...|\n",
      "|         E5|Employee_56|             Finance|-69096|   6/12/2021| Employee56@Compa...|\n",
      "|        E50|Employee_57|                  HR|-67787|  12/22/2022| Employee57@Compa...|\n",
      "|        E67|Employee_58|             Finance|  NULL|    2/6/2021| Employee58@Compa...|\n",
      "|        E42|Employee_60|                  IT|  NULL|   5/11/2021| Employee60@Compa...|\n",
      "|        E87|Employee_61|             finance|-89166|  27-01-2022| Employee61@Compa...|\n",
      "|        E37|Employee_62|               Sales|-58173|   6/23/2021| Employee62@Compa...|\n",
      "|        E66|Employee_63|     Human Resources|  NULL|    8/4/2020| Employee63@Compa...|\n",
      "|        E12|Employee_64|                  IT|-79226|   12/2/2020| Employee64@Compa...|\n",
      "|        E90|Employee_66|                  hr|  NULL|    9/5/2022| Employee66@Compa...|\n",
      "|        E14|Employee_67|               sales|  NULL|    9/8/2021| Employee67@Compa...|\n",
      "|        E58|Employee_70|               sales|-79268|   9/19/2021| Employee70@Compa...|\n",
      "|        E36|Employee_71|                  IT|-35077|   7/10/2020| Employee71@Compa...|\n",
      "|        E70|Employee_72|             finance|  NULL|  22-11-2022| Employee72@Compa...|\n",
      "|        E42|Employee_79|             finance|-59799|   7/23/2020| Employee79@Compa...|\n",
      "|        E84|Employee_81|                  IT|  NULL|   2/11/2019| Employee81@Compa...|\n",
      "|        E76|Employee_85|     Human Resources|  NULL|  11/28/2022| Employee85@Compa...|\n",
      "|        E20|Employee_88|               sales|-41543|   9/17/2021| Employee88@Compa...|\n",
      "|        E76|Employee_89|     Human Resources|  NULL|   7/25/2020| Employee89@Compa...|\n",
      "|        E24|Employee_91|             Finance|-43901|   7/26/2020| Employee91@Compa...|\n",
      "|        E38|Employee_94|Information Techn...|  NULL|   9/21/2022| Employee94@Compa...|\n",
      "|        E25|Employee_97|               sales|-78405|    5/7/2022| Employee97@Compa...|\n",
      "|        E25|Employee_98|Information Techn...|  NULL|   1/29/2019| Employee98@Compa...|\n",
      "|        E36|Employee_99|                  hr|-33573|   7/30/2022| Employee99@Compa...|\n",
      "+-----------+-----------+--------------------+------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_invalid_salary=df_raw.filter(\n",
    "    (col(\"salary\").isNull()) |\n",
    "    (col(\"salary\")==\"\") |\n",
    "    (regexp_replace(col(\"salary\"), \",\", \"\").cast(\"double\").isNull()) |\n",
    "    (regexp_replace(col(\"salary\"),\",\",\"\").cast(\"double\") < 0)\n",
    ")\n",
    "\n",
    "df_invalid_salary.show(100)\n",
    "\n",
    "df_invalid_salary.coalesce(1)\\\n",
    ".write.mode(\"overwrite\")\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".csv(\"../output/invalid_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77983f",
   "metadata": {},
   "source": [
    "## 7. REPORT CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3e895",
   "metadata": {},
   "source": [
    "### 7.1 Total salary expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6e9c1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|  3771350.0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#total salary expense\n",
    "df_clean.select(sum(\"salary\")).show()\n",
    "\n",
    "df_clean.write.mode(\"overwrite\")\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".csv(\"../output/reports/total_salary_expenses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e2ecf",
   "metadata": {},
   "source": [
    "### 7.2 Employee count per department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5b4c7904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          department|count|\n",
      "+--------------------+-----+\n",
      "|               Sales|   13|\n",
      "|Information Techn...|   16|\n",
      "|             Finance|   19|\n",
      "|     Human Resources|   14|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.groupBy(\"department\").count().show()\n",
    "\n",
    "df_clean.coalesce(1).write.mode(\"overwrite\")\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".csv(\"../output/reports/employee_per_department\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a87c4",
   "metadata": {},
   "source": [
    "### 7.3 Average salary per department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "08bf85e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|          department|        avg_salary|\n",
      "+--------------------+------------------+\n",
      "|               Sales|           72166.0|\n",
      "|Information Techn...|         46622.875|\n",
      "|             Finance| 65903.84210526316|\n",
      "|     Human Resources|59646.642857142855|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.groupBy(\"department\").agg(\n",
    "    avg(\"salary\").alias(\"avg_salary\")\n",
    ").show()\n",
    "\n",
    "df_clean.coalesce(1).write.mode(\"overwrite\")\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".csv(\"../output/reports/average_salary_per_department\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25578be4",
   "metadata": {},
   "source": [
    "### 7.4 Hiring trend by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1a6401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|joining_month|count|\n",
      "+-------------+-----+\n",
      "|      2019-01|    2|\n",
      "|      2019-02|    1|\n",
      "|      2019-04|    3|\n",
      "|      2019-05|    2|\n",
      "|      2019-07|    3|\n",
      "|      2019-08|    1|\n",
      "|      2019-09|    3|\n",
      "|      2019-11|    2|\n",
      "|      2020-01|    2|\n",
      "|      2020-02|    2|\n",
      "|      2020-03|    1|\n",
      "|      2020-04|    1|\n",
      "|      2020-06|    3|\n",
      "|      2020-07|    1|\n",
      "|      2020-11|    1|\n",
      "|      2020-12|    1|\n",
      "|      2021-02|    2|\n",
      "|      2021-03|    2|\n",
      "|      2021-05|    2|\n",
      "|      2021-06|    2|\n",
      "|      2021-08|    1|\n",
      "|      2021-09|    3|\n",
      "|      2021-11|    3|\n",
      "|      2022-01|    1|\n",
      "|      2022-02|    1|\n",
      "|      2022-04|    1|\n",
      "|      2022-05|    2|\n",
      "|      2022-08|    1|\n",
      "|      2022-09|    3|\n",
      "|      2022-10|    1|\n",
      "|      2022-11|    3|\n",
      "|      2022-12|    2|\n",
      "|      2023-01|    1|\n",
      "|      2023-02|    2|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.groupBy(\n",
    "    date_format(\"joining_date\",\"yyyy-MM\").alias(\"joining_month\")\n",
    "    ).count().orderBy(\"joining_month\").show(100)\n",
    "\n",
    "df_clean.coalesce(1).write.mode(\"overwrite\")\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".csv(\"../output/reports/hiring_trend_by_month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54daf3",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "After completing data cleaning and validation, exploratory analysis was performed to generate key HR insights.\n",
    "\n",
    "1. Total Salary Expense\n",
    "\n",
    "Total Payroll Cost: 3,771,350\n",
    "\n",
    "This represents the organization’s total salary expenditure after data correction and imputation.\n",
    "\n",
    "\n",
    "2. Employee Distribution by Department\n",
    "\n",
    "|Department|Employee_Count| \n",
    "|--|--|\n",
    "|Finance|19| \n",
    "|IT|6| \n",
    "|HR|14|\n",
    "|Slaes|13|\n",
    "\n",
    "Insight:\n",
    "Finance has the highest employee count, suggesting greater operational staffing requirements compared to other departments.\n",
    "\n",
    "3. Average Salary by Department\n",
    "\n",
    "|Department|Average_Salary|\n",
    "|--|--|\n",
    "|Sales|72,166|\n",
    "|Finance|65,903|\n",
    "|HR|59,646|\n",
    "|IT|46,622|\n",
    "\n",
    "Insight:\n",
    "Sales has the highest average salary, while Information Technology has the lowest. This may reflect commission structures, role hierarchy, or compensation strategy differences across departments.\n",
    "\n",
    "4. Hiring Trend Analysis (2019-2021)\n",
    "\n",
    "Joining dates were aggregated by month (YYYY-MM) to analyze recruitment patterns.\n",
    "\n",
    "Months with highest hiring count (3):\n",
    "- 2019-04\n",
    "- 2019-07\n",
    "- 2019-09\n",
    "- 2020-06\n",
    "- 2021-09\n",
    "- 2021-11\n",
    "- 2022-09\n",
    "- 2022-11\n",
    "There are multiple moderate peaks, not just a few isolated ones.\n",
    "\n",
    "Conclusion:\n",
    "The organization maintained steady recruitment activity without significant expansion or contraction periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903fbeb",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Project Summary\n",
    "\n",
    "#### Final Project Summary – HR Data Cleaning & Analysis\n",
    "\n",
    "##### Project Overview:-\n",
    "This project focused on building a structured data cleaning and validation workflow for an HR employee dataset using PySpark.\n",
    "The raw dataset contained\n",
    "- Duplicate records\n",
    "\n",
    "- Missing salary values\n",
    "\n",
    "- Negative salary entries\n",
    "\n",
    "- Inconsistent department naming\n",
    "\n",
    "- Mixed date formats\n",
    "\n",
    "- Unstructured salary formatting\n",
    "The objective was to design a reproducible transformation process to produce a standardized, analytics-ready dataset.\n",
    "\n",
    "##### Data Engineering Tasks Performed\n",
    "\n",
    "The following transformation steps were implemented:\n",
    "\n",
    "- Removed duplicate records using employee_id as primary key\n",
    "\n",
    "- Standardized salary format (removed commas, cast to numeric)\n",
    "\n",
    "- Identified and handled negative salary values\n",
    "\n",
    "- Treated invalid salary entries as missing\n",
    "\n",
    "- Imputed missing salaries using department-level median\n",
    "\n",
    "- Created salary_flag column to maintain audit traceability\n",
    "\n",
    "- Standardized department values\n",
    "\n",
    "- Normalized date format to YYYY-MM-DD\n",
    "\n",
    "- Cleaned and normalized email formatting\n",
    "\n",
    "- Enforced final schema for downstream compatibility\n",
    "\n",
    "##### Data Quality Impact\n",
    "\n",
    "- Total records processed: 62\n",
    "\n",
    "- Salary records corrected or imputed: 30\n",
    "\n",
    "- Final dataset contains no null salary values\n",
    "\n",
    "- Schema standardized for reliable downstream consumption\n",
    "\n",
    "##### Validation & Aggregation Checks\n",
    "\n",
    "- Post-transformation validation queries were executed to verify:\n",
    "\n",
    "- Total payroll consistency\n",
    "\n",
    "- Department-level employee distribution\n",
    "\n",
    "- Average salary by department\n",
    "\n",
    "- Hiring distribution across months\n",
    "\n",
    "These checks confirm transformation accuracy and data integrity.\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "This project demonstrates practical Data Engineering skills including:\n",
    "\n",
    "- Data quality validation\n",
    "\n",
    "- Schema standardization\n",
    "\n",
    "- Controlled imputation strategy\n",
    "\n",
    "- Audit flag implementation\n",
    "\n",
    "- Aggregation-based validation\n",
    "\n",
    "- Building transformation logic using PySpark\n",
    "\n",
    "The final dataset is structured, validated, and ready for reporting, dashboarding, or pipeline integration.\n",
    "\n",
    "---\n",
    "\n",
    "### End of Project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
